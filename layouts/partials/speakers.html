<h2 class="section-title">{{ .titles.speakers.title }}</h2>

<p><a href="https://zicokolter.com">Zico Kolter</a> (Associate Professor, Carnegie Mellon University)</p>

<p><b>Title: Incorporating robust control guarantees within (deep) 
reinforcement learning</b></p>

<p>Abstract: Reinforcement learning methods have produced breakthrough 
results in recent years, but their application to safety-critical 
systems has been substantially limited by their lack of guarantees, such 
as those provided by modern robust control techniques.  In this talk, I 
will discuss a technique we have recently developed that embeds 
robustness guarantees inside of arbitrary RL policy classes.  Using this 
approach, we can build deep RL methods that attain much of the 
performance advantages of modern deep RL (namely, superior performance 
in "average case" scenarios), while still maintaining robustness in 
worst-case adversarial settings.  I will highlight experimental results 
on several simple control systems highlighting the benefits of the 
method, in addition to a larger-scale smart grid setting, and end by 
discussing future directions in this line of work.</p>

<p>Bio: Dr Kolter is an Associate Professor in the Computer Science Department with 
  the School of Computer Science at Carnegie Mellon University. In addition, 
  he also serves as Chief Scientist of AI Research for the Bosch Center for AI (BCAI), 
  working in the Pittsburgh Office. His research group focuses on machine learning, optimization, 
  and control. Specifically, much of the research aims at making deep learning algorithms safer, 
  more robust, and more explainable; to these ends, we have worked on methods for 
  training provably robust deep learning systems, and including more complex “modules” 
  (such as optimization solvers) within the loop of deep architectures. Further focus is on 
  several application domains, with a particular focus on applications in smart energy and sustainability domains.</p>
