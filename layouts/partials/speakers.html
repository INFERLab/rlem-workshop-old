<h2 class="section-title">{{ .titles.speakers.title }}</h2>

<p><a href="https://zicokolter.com">Zico Kolter</a> (Associate Professor, Carnegie Mellon University)</p>

<p><b>Title: Incorporating robust control guarantees within (deep) 
reinforcement learning</b></p>

<p>Abstract: Reinforcement learning methods have produced breakthrough 
results in recent years, but their application to safety-critical 
systems has been substantially limited by their lack of guarantees, such 
as those provided by modern robust control techniques.  In this talk, I 
will discuss a technique we have recently developed that embeds 
robustness guarantees inside of arbitrary RL policy classes.  Using this 
approach, we can build deep RL methods that attain much of the 
performance advantages of modern deep RL (namely, superior performance 
in "average case" scenarios), while still maintaining robustness in 
worst-case adversarial settings.  I will highlight experimental results 
on several simple control systems highlighting the benefits of the 
method, in addition to a larger-scale smart grid setting, and end by 
discussing future directions in this line of work.</p>
